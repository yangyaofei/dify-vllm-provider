provider: vllm
label:
  en_US: Vllm
description:
  en_US: Models provided by vllm with guided inference supported.
  zh_Hans: Vllm openai guided 支持
icon_small:
  en_US: vLLM-Logo.svg
icon_large:
  en_US: vLLM-Logo.svg
background: "#E5E7EB"
supported_model_types:
  - llm
configurate_methods:
  - customizable-model
model_credential_schema:
  model:
    label:
      en_US: Model Name
      zh_Hans: 模型名称
    placeholder:
      en_US: Enter your model name
      zh_Hans: 输入模型名称
  credential_form_schemas:
    - variable: api_key
      label:
        en_US: API Key
      type: secret-input
      required: false
      placeholder:
        zh_Hans: 在此输入您的 API Key
        en_US: Enter your API Key
    - variable: endpoint_url
      label:
        zh_Hans: API endpoint URL
        en_US: API endpoint URL
      type: text-input
      required: true
      placeholder:
        zh_Hans: Base URL, e.g. https://api.openai.com/v1
        en_US: Base URL, e.g. https://api.openai.com/v1
    - variable: endpoint_model_name
      label:
        zh_Hans: API endpoint中的模型名称
        en_US: model name for API endpoint
      type: text-input
      required: false
      placeholder:
        zh_Hans: endpoint model name, e.g. chatgpt4.0
        en_US: endpoint model name, e.g. chatgpt4.0
    - variable: mode
      show_on:
        - variable: __model_type
          value: llm
      label:
        en_US: Completion mode
      type: select
      required: false
      default: chat
      placeholder:
        zh_Hans: 选择对话类型
        en_US: Select completion mode
      options:
        - value: completion
          label:
            en_US: Completion
            zh_Hans: 补全
        - value: chat
          label:
            en_US: Chat
            zh_Hans: 对话
    - variable: context_size
      label:
        zh_Hans: 模型上下文长度
        en_US: Model context size
      required: true
      show_on:
        - variable: __model_type
          value: llm
      type: text-input
      default: '4096'
      placeholder:
        zh_Hans: 在此输入您的模型上下文长度
        en_US: Enter your Model context size
    - variable: max_tokens_to_sample
      label:
        zh_Hans: 最大 token 上限
        en_US: Upper bound for max tokens
      show_on:
        - variable: __model_type
          value: llm
      default: '4096'
      type: text-input
    - variable: agent_though_support
      show_on:
        - variable: __model_type
          value: llm
      label:
        en_US: Agent Thought
      type: select
      required: false
      default: not_supported
      options:
        - value: supported
          label:
            en_US: Support
            zh_Hans: 支持
        - value: not_supported
          label:
            en_US: Not Support
            zh_Hans: 不支持
    - variable: function_calling_type
      show_on:
        - variable: __model_type
          value: llm
      label:
        en_US: Function calling
      type: select
      required: false
      default: no_call
      options:
        - value: function_call
          label:
            en_US: Function Call
            zh_Hans: Function Call
        - value: tool_call
          label:
            en_US: Tool Call
            zh_Hans: Tool Call
        - value: no_call
          label:
            en_US: Not Support
            zh_Hans: 不支持
    - variable: stream_function_calling
      show_on:
        - variable: __model_type
          value: llm
      label:
        en_US: Stream function calling
      type: select
      required: false
      default: not_supported
      options:
        - value: supported
          label:
            en_US: Support
            zh_Hans: 支持
        - value: not_supported
          label:
            en_US: Not Support
            zh_Hans: 不支持
    - variable: vision_support
      show_on:
        - variable: __model_type
          value: llm
      label:
        zh_Hans: Vision 支持
        en_US: Vision Support
      type: select
      required: false
      default: no_support
      options:
        - value: support
          label:
            en_US: Support
            zh_Hans: 支持
        - value: no_support
          label:
            en_US: Not Support
            zh_Hans: 不支持
    - variable: stream_mode_delimiter
      label:
        zh_Hans: 流模式返回结果的分隔符
        en_US: Delimiter for streaming results
      show_on:
        - variable: __model_type
          value: llm
      default: '\n\n'
      type: text-input
extra:
  python:
    provider_source: provider/vllm.py
    model_sources:
      - "models/llm/llm.py"
